{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","import json\n","import cv2\n","import numpy as np\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class KeypointsDataset(Dataset):\n","    def __init__(self, img_dir, data_file):\n","        self.img_dir = img_dir\n","        with open(data_file, \"r\") as f:\n","            self.data = json.load(f)\n","        \n","        self.transforms = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n","        h,w = img.shape[:2]\n","\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = self.transforms(img)\n","        kps = np.array(item['kps']).flatten()\n","        kps = kps.astype(np.float32)\n","\n","        kps[::2] *= 224.0 / w\n","        kps[1::2] *= 224.0 / h\n","\n","        return img, kps\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = KeypointsDataset(\"/kaggle/input/court-keypoints/data/images\",\"/kaggle/input/court-keypoints/data/data_train.json\")\n","val_dataset = KeypointsDataset(\"/kaggle/input/court-keypoints/data/images\",\"/kaggle/input/court-keypoints/data/data_val.json\")\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ChannelAttention(nn.Module):\n","    def __init__(self, channel, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n"," \n","        self.shared_MLP = nn.Sequential(\n","            nn.Conv2d(channel, channel // ratio, 1, bias=False),\n","            nn.ReLU(),\n","            nn.Conv2d(channel // ratio, channel, 1, bias=False)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n"," \n","    def forward(self, x):\n","        avgout = self.shared_MLP(self.avg_pool(x))\n","        maxout = self.shared_MLP(self.max_pool(x))\n","        return self.sigmoid(avgout + maxout)\n"," \n","class SpatialAttention(nn.Module):\n","    def __init__(self):\n","        super(SpatialAttention, self).__init__()\n","        self.conv2d = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3)\n","        self.sigmoid = nn.Sigmoid()\n"," \n","    def forward(self, x):\n","        avgout = torch.mean(x, dim=1, keepdim=True)\n","        maxout, _ = torch.max(x, dim=1, keepdim=True)\n","        out = torch.cat([avgout, maxout], dim=1)\n","        out = self.sigmoid(self.conv2d(out))\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class KeypointResNet50(nn.Module):\n","    def __init__(self):\n","        super(KeypointResNet50, self).__init__()\n","        self.backbone = models.resnet50(pretrained=True)\n","        self.backbone.fc = nn.Identity()  \n","\n","        self.channel_attention = ChannelAttention(2048)\n","        self.spatial_attention = SpatialAttention()\n","\n","        self.fc = nn.Linear(models.resnet50(pretrained=True).fc.in_features, 14 * 2)\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        #x = self.channel_attention(x) * x\n","        #x = self.spatial_attention(x) * x\n","\n","        #x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n","        #x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = KeypointResNet50()\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epochs = 20\n","for epoch in range(epochs):\n","    model.train()\n","    for i, (imgs, kps) in enumerate(train_loader):\n","        imgs = imgs.to(device)\n","        kps = kps.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        loss = criterion(outputs, kps)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 10 == 0:\n","            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0\n","        for imgs, kps in val_loader:\n","            imgs = imgs.to(device)\n","            kps = kps.to(device)\n","\n","            outputs = model(imgs)\n","            loss = criterion(outputs, kps)\n","            val_loss += loss.item()\n","\n","        val_loss /= len(val_loader)\n","        print(f\"Epoch {epoch}, val loss: {val_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.stat_dict(), \"keypoints_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMmw5kBwBVG8CmN3rLenh9L","gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5279262,"sourceId":8782423,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
